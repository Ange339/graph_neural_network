# Data directory
dir: ../data_sample
books_filename: books_filtered.parquet
users_filename: users_filtered.parquet
interactions_filename: interactions.parquet
descriptions_filename: descriptions_filtered.parquet
reviews_filename: reviews_filtered.parquet
embeddings_descriptions_filename: embeddings_descriptions_sbert_pt.parquet
embeddings_reviews_filename: embeddings_reviews_sbert_pt.parquet


# Processing settings
review_coreness_k: 5
coreness_k: 10
language_filter: True
edge_type: reads # "interactions", "reads", "rates"


# Embedding feature strategies
user_features:
  - name: topo
    features: ["degree", "coreness"]
    degree_log_transform: true
  - name: textual_reviews
    aggr_fn: mean

book_features:
  - name: topo
    features: ["degree", "coreness"]
    degree_log_transform: true
  - name: textual_desc
  - name: textual_reviews
    aggr_fn: mean


# Splitting settings
seed: 1
val_size: 0.2
test_size: 0.2
disjoint_train_ratio: 0.0 # set to 0.0 for transductive learning

# Batch sampling settings
batch_size: 128
batch_method: "binary_link_neighbors"
num_neighbors: [10, 10] # N_users, N_Items

# Model hyperparameters
hidden_channels: 32
latent_dim: 16
n_layer: 1
user_emb_dim: 64
item_emb_dim: 64
user_feature_linear: true
item_feature_linear: true
feature_linear_dim: 64
feature_aggr_method: "concat" # "concat", "add", "mean", "max"
dropout: 0.5
skip_connection: false
batch_norm: false
encoder: sage_encoder
decoder: inner_product_decoder
variational: true

# Training settings
negative_sampling_method: "pairwise_random" # "batch_random",  "pairwise_random"
negative_sampling_recurrence: "epoch" # "epoch", "fixed"
negative_sampling_ratio: 1.0
epochs: 1
learning_rate: 0.01
weight_decay: 0.00001
opt_decay_step: 20
opt_decay_rate: 0.1
recon_loss: "bpr" # "binary", "bpr", "bce"
kl_beta: 1.0
kl_warmup_epoch: 50
eval_interval: 1
patience: 50
save_model: false
tsne_visualization: true