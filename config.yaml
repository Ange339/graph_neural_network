# Data directory
dir: ./data_sample
books_filename: books_filtered.parquet
users_filename: users_filtered.parquet
interactions_filename: interactions.parquet
descriptions_filename: descriptions_filtered.parquet
reviews_filename: reviews_filtered.parquet
embeddings_descriptions_filename: embeddings_descriptions_sbert_pt.parquet
embeddings_reviews_filename: embeddings_reviews_sbert_pt.parquet


# Processing settings
review_coreness_k: 5
coreness_k: 10
language_filter: True


# Embedding feature strategies
user_features:
  # - name: topo
  #   features: ["degree", "coreness"]
  #   degree_log_transform: true
  - name: random
    dim: 64
    xavier_init: true
  # - name: textual_reviews
  #   aggr_fn: mean

book_features:
  # - name: topo
  #   features: ["degree", "coreness"]
  #   degree_log_transform: true
  - name: random
    dim: 64
    xavier_init: true
  # - name: textual_desc
  # - name: textual_reviews
  #   aggr_fn: mean


# Splitting settings
seed: 42
val_size: 0.1
test_size: 0.1
disjoint_train_ratio: 0.0 # set to 0.0 for transductive learning

# Batch sampling settings
batch_size: 64
batch_method: "binary_link_neighbors"
num_neighbors: [20, 10] # N_users, N_Items

# Model hyperparameters
hidden_channels: 32
latent_dim: 16
n_layer: 2
skip_connection: false
batch_norm: false
gnn_layer_cls: gat_conv
n_heads: 5
dropout: 0.3
encoder: vgae_encoder
decoder: inner_product_decoder
emb_linear_transform: false

# Training settings
negative_sampling_method: "batch_random"
negative_sampling_ratio: 10.0
epochs: 10
learning_rate: 0.01
weight_decay: 0.00001
recon_loss: "binary"
eval_interval: 1
patience: 50
save_model: true