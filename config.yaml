# Data directory
dir: ../data_sample
out_dir: output_sample
books_filename: books_filtered.parquet
users_filename: users_filtered.parquet
interactions_filename: interactions.parquet
descriptions_filename: descriptions_filtered.parquet
reviews_filename: reviews_filtered.parquet
embeddings_descriptions_filename: embeddings_descriptions_sbert_pt.parquet
embeddings_reviews_filename: embeddings_reviews_sbert_pt.parquet


# Processing settings
review_coreness_k: 5
coreness_k: 5
language_filter: True
edge_type: interactions # "interactions", "reads", "rates"


# Embedding feature strategies
user_features:
  # - name: topo
  #   features: ["degree", "coreness"]
  #   degree_log_transform: true
  - name: textual_reviews
    aggr_fn: mean

book_features:
  # - name: topo
  #   features: ["degree", "coreness"]
  #   degree_log_transform: true
  - name: textual_desc
  - name: textual_reviews
    aggr_fn: mean


# Splitting settings
seed: 42
val_size: 0.2
test_size: 0.2
disjoint_train_ratio: 0.0 # set to 0.0 for transductive learning

# Batch sampling settings
batch_size: 512
batch_method: "binary_link_neighbors" # "binary_link_neighbors", "node_neighbors"
num_neighbors: [20, 10]

# Model hyperparameters
hidden_channels: 32
latent_dim: 16
n_layer: 1
user_emb_dim: 64
item_emb_dim: 64
user_feature_linear: true
item_feature_linear: true
feature_linear_dim: 64
feature_aggr_method: "concat" # "concat", "add", "mean", "max"
dropout: 0.5
skip_connection: null # "sum", "concat", None
batch_norm: true
heads: 2
encoder: sage_encoder
decoder: inner_product_decoder
variational: true

# Training settings
negative_sampling_method: "batch_random" # "batch_random",  "pairwise_random"
negative_sampling_recurrence: "epoch" # "epoch", "fixed"
negative_sampling_ratio: 30
retrieval_k: 300
epochs: 50
learning_rate: 0.01
weight_decay: 0.00001
opt_decay_step: 20
opt_decay_rate: 0.1
recon_loss: "binary" # "binary", "bpr", "bce"
kl_beta: 1.0
kl_warmup_epoch: 50
eval_interval: 1
patience: 50
save_model: true
tsne_visualization: true