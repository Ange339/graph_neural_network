{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4aded2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "vJMG8gbuQ5g2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25729,
     "status": "ok",
     "timestamp": 1755874642037,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "vJMG8gbuQ5g2",
    "outputId": "ce3cc13e-c2c9-4ae4-ad9b-920d3d1dbce1"
   },
   "outputs": [],
   "source": [
    "# !pip install igraph\n",
    "# !pip install scikit-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "471eb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12f3add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pytorch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9247b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import os\n",
    "# print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "\n",
    "# srs_url = f\"https://pytorch-geometric.com/whl/torch-{torch.__version__}.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3843554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch_scatter -f $srs_url\n",
    "# !pip install torch_sparse -f $srs_url\n",
    "# !pip install torch_cluster -f $srs_url\n",
    "# !pip install torch_spline_conv -f $srs_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d2c07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "Voe3ED3WRFsV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53284,
     "status": "ok",
     "timestamp": 1755874695512,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "Voe3ED3WRFsV",
    "outputId": "9b8f371c-ce89-4da5-9165-484c8e266a9f"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import os\n",
    "# print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#   !pip install torch==2.4.0\n",
    "\n",
    "# # Install torch geometric\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#   torch_version = str(torch.__version__)\n",
    "#   scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "#   sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "#   !pip install torch-scatter -f $scatter_src\n",
    "#   !pip install torch-sparse -f $sparse_src\n",
    "#   !pip install torch-geometric\n",
    "#   !pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e675cc97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3286,
     "status": "ok",
     "timestamp": 1755874723445,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "e675cc97",
    "outputId": "7634e6dd-140e-4f9e-dcf4-2a361ca3547c"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import scipy.sparse as sp\n",
    "from typing import Literal\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "#%env NX_CUGRAPH_AUTOCONFIG=True\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite, community\n",
    "nx.config.warnings_to_ignore.add(\"cache\")\n",
    "\n",
    "import igraph as ig\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, VGAE, to_hetero\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler  import NegativeSampling\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from torch_scatter import scatter_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46012f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import GraphLoader\n",
    "from src.batch_loader import BatchLoader\n",
    "from src.utils import *\n",
    "from src.registry import GNN_LAYER_REGISTRY, GNN_MODEL_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bb194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "{'batch_method': 'binary_link_neighbors',\n",
      " 'batch_size': 128,\n",
      " 'book_features': [{'degree_log_transform': True,\n",
      "                    'features': ['degree', 'coreness'],\n",
      "                    'name': 'topo'},\n",
      "                   {'dim': 128, 'name': 'random', 'xavier_init': True}],\n",
      " 'books_filename': 'books_filtered.parquet',\n",
      " 'coreness_k': 10,\n",
      " 'descriptions_filename': 'descriptions_filtered.parquet',\n",
      " 'dir': 'G:/My Drive/thesis/data_sample',\n",
      " 'disjoint_train_ratio': 0.0,\n",
      " 'dropout': 0.3,\n",
      " 'embeddings_descriptions_filename': 'embeddings_descriptions_sbert_pt.parquet',\n",
      " 'embeddings_reviews_filename': 'embeddings_reviews_sbert_pt.parquet',\n",
      " 'epochs': 100,\n",
      " 'gnn_layer_cls': 'gcn_conv',\n",
      " 'hidden_channels': 128,\n",
      " 'interactions_filename': 'interactions.parquet',\n",
      " 'language_filter': True,\n",
      " 'latent_dim': 64,\n",
      " 'learning_rate': 0.001,\n",
      " 'negative_sampling_method': 'random',\n",
      " 'num_layers': 3,\n",
      " 'num_neighbors': [10, 10],\n",
      " 'review_coreness_k': 3,\n",
      " 'reviews_filename': 'reviews_filtered.parquet',\n",
      " 'seed': 42,\n",
      " 'test_size': 0.1,\n",
      " 'user_features': [{'degree_log_transform': True,\n",
      "                    'features': ['degree', 'coreness'],\n",
      "                    'name': 'topo'},\n",
      "                   {'dim': 128, 'name': 'random', 'xavier_init': True}],\n",
      " 'users_filename': 'users_filtered.parquet',\n",
      " 'val_size': 0.1}\n",
      "\n",
      "\n",
      "Initial size. Users: 43807, Books: 236065, Total: 279872, Edges: 1134132, Density: 0.010967%\n",
      "Filtered size. Users: 3150, Books: 3568, Total: 6718, Edges: 162479, Density: 1.445646%\n",
      "Initial textual embeddings size. Descriptions: 3568, Reviews: 30939, Total: 34507\n",
      "Filtered textual embeddings size. Descriptions: 3568, Reviews: 29451, Total: 33019\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "dir_ = pathlib.Path().resolve()\n",
    "\n",
    "# Parser\n",
    "parser = argparse.ArgumentParser(description=\"Load parquet datasets\")\n",
    "parser.add_argument(\"--config\", type=str, default=f\"{dir_}/config.yaml\", help=\"Path to YAML config file\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "with open(args.config, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "pprint(cfg)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Prepare the data\n",
    "graph_loader = GraphLoader(cfg)\n",
    "graph_data = graph_loader.load()\n",
    "\n",
    "# Split the data into train/val/test sets\n",
    "train_val_test_split = random_link_split(cfg)\n",
    "train_data, val_data, test_data = train_val_test_split(graph_data)\n",
    "\n",
    "# batch loader\n",
    "batch_loader = BatchLoader(cfg)\n",
    "train_loader = batch_loader.load(train_data, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "def batch_random_sample(self, batch_data, negative_sampling_ratio):\n",
    "    \"Randomly sample negative examples from the batch dataset\"\n",
    "    num_neg_samples = int(len(batch_data['user', 'interacts', 'item'].edge_label_index[0]) * negative_sampling_ratio)\n",
    "    edge_label_index = batch_data['user', 'interacts', 'item'].edge_label_index\n",
    "    negative_samples = negative_sampling(edge_label_index, num_neg_samples=num_neg_samples)\n",
    "    return negative_samples, torch.zeros(num_neg_samples, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ab44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 cfg\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        gnn_layer_cls: class of the GNN layer (e.g., GCNConv, SAGEConv)\n",
    "        encoder_cls: class of the encoder (should accept gnn_layer_cls, in_channels, hidden_channels, latent_dim)\n",
    "        decoder_cls: class of the decoder (should accept no arguments)\n",
    "        in_channels: input feature dimension\n",
    "        hidden_channels: hidden layer dimension\n",
    "        latent_dim: latent space dimension\n",
    "        encoder_kwargs: additional kwargs for encoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer_cls=GNN_LAYER_REGISTRY[cfg['gnn_layer_cls']]\n",
    "        encoder=GNN_MODEL_REGISTRY[cfg['encoder']]\n",
    "        decoder=GNN_MODEL_REGISTRY[cfg['decoder']]\n",
    "        user_in_channels=data[\"user\"].num_features\n",
    "        item_in_channels=data[\"item\"].num_features\n",
    "        hidden_channels=cfg['hidden_channels']\n",
    "        latent_dim=cfg['latent_dim']\n",
    "        emb_linear_transform=cfg.get('emb_linear_transform', False)\n",
    "\n",
    "        self.emb_linear_transform = cfg.get('emb_linear_transform', False)\n",
    "        self.user_linear = nn.Linear(user_in_channels, hidden_channels)\n",
    "        self.item_linear = nn.Linear(item_in_channels, hidden_channels)\n",
    "\n",
    "        if user_in_channels != item_in_channels:\n",
    "            print(f\"Inconsistent input feature dimensions: user={user_in_channels}, item={item_in_channels}\")\n",
    "            print(f\"Forcing linear transformation\")\n",
    "            self.emb_linear_transform = True\n",
    "\n",
    "        elif user_in_channels == item_in_channels == hidden_channels:\n",
    "            print(f\"Consistent input feature dimensions: user={user_in_channels}, item={item_in_channels}, hidden={hidden_channels}\")\n",
    "            print(f\"Disabling linear transformation\")\n",
    "            self.emb_linear_transform = False\n",
    "\n",
    "        input_channels = hidden_channels if self.emb_linear_transform else user_in_channels\n",
    "\n",
    "        self.encoder = encoder(gnn_layer_cls, input_channels, hidden_channels, latent_dim)\n",
    "        self.decoder = decoder()\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, data):\n",
    "        if self.emb_linear_transform:\n",
    "            user_x = self.user_linear(data[\"user\"].x)\n",
    "            item_x = self.item_linear(data[\"item\"].x)\n",
    "        else:\n",
    "            user_x = data[\"user\"].x\n",
    "            item_x = data[\"item\"].x\n",
    "\n",
    "        x = torch.cat([user_x, item_x], dim=0)\n",
    "        edge_index = data['user', 'interacts', 'item'].edge_index\n",
    "\n",
    "        mu, logvar = self.encoder(x, edge_index)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return self.decoder(z, edge_index)\n",
    "\n",
    "\n",
    "\n",
    "class VGAEncoder(nn.Module):\n",
    "    def __init__(self, GNNLayer, in_channels, hidden_channels, latent_dim):\n",
    "        \"\"\"\n",
    "        in_channels: dimension of the node input features (after projecting items and using user embeddings)\n",
    "        hidden_channels: hidden units for first GCN layer\n",
    "        latent_dim: dimension of mu and logvar\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = GNNLayer(in_channels, hidden_channels)\n",
    "        self.conv_mu = GNNLayer(hidden_channels, latent_dim)\n",
    "        self.conv_logvar = GNNLayer(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "class InnerProductDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "        edge_feat_user = z[edge_index[0]]\n",
    "        edge_feat_item = z[edge_index[1]]\n",
    "        preds = (edge_feat_user * edge_feat_item).sum(dim=-1)\n",
    "        if sigmoid:\n",
    "            preds = torch.sigmoid(preds)\n",
    "        return preds\n",
    "    \n",
    "    def forward_all(self, z, sigmoid=True):\n",
    "        \"Use it cautiously, as it computes all pairwise interactions\"\n",
    "        A_pred = (z @ z.T).view(-1)\n",
    "        if sigmoid:\n",
    "            A_pred = torch.sigmoid(A_pred)\n",
    "        return A_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4090a2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[3150, 130] },\n",
       "  item={ x=[3568, 130] },\n",
       "  (user, interacts, item)={\n",
       "    edge_index=[2, 129985],\n",
       "    edge_label=[32494],\n",
       "    edge_label_index=[2, 32494],\n",
       "  },\n",
       "  (item, rev_interacts, user)={ edge_index=[2, 129985] }\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = val_data.to(device)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03db4fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label = val_data[\"user\", \"interacts\", \"item\"].edge_label\n",
    "mask = edge_label == 1\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f522968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 547, 1073,  340,  ..., 1693, 1231, 1682],\n",
       "        [ 851,  264,  220,  ...,   35, 2060, 3232]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label_index = val_data[\"user\", \"interacts\", \"item\"].edge_label_index\n",
    "edge_label_index[:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b581173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_recon_loss(z, pos_preds, neg_preds):\n",
    "\n",
    "    pos_loss = -torch.log(pos_preds + 1e-15).mean()\n",
    "    neg_loss = -torch.log(1 - neg_preds + 1e-15).mean()\n",
    "\n",
    "    return pos_loss + neg_loss\n",
    "\n",
    "def kl_loss(mu, logvar):\n",
    "    kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1e7517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.55%\n"
     ]
    }
   ],
   "source": [
    "x = 0.5555\n",
    "print(f\"{x:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a452dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(y_scores, y_true):\n",
    "    y_true = y_true.long() \n",
    "    score = AUROC(task=\"binary\")(y_scores, y_true).item()\n",
    "    return score\n",
    "\n",
    "def compute_average_precision(y_scores, y_true):\n",
    "    y_true = y_true.long() \n",
    "    score = AveragePrecision(task=\"binary\")(y_scores, y_true).item()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def batch_evaluate(loader, model):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_recon = 0\n",
    "    total_loss_kl = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            z, mu, logvar = model(batch)\n",
    "            positive_index = batch[\"user\", \"interacts\", \"item\"].edge_label_index\n",
    "            positive_labels = torch.ones(positive_index.size(0), dtype=torch.float32)\n",
    "            if sampling_strategy == \"batch_random\":\n",
    "                negative_index, negative_labels = negative_sampler.batch_random_sample(batch)\n",
    "\n",
    "            pos_preds = model.decode(z, positive_index)\n",
    "            neg_preds = model.decode(z, negative_index)\n",
    "\n",
    "            preds = torch.cat([pos_preds, neg_preds])\n",
    "            edge_labels = torch.cat([positive_labels, negative_labels])\n",
    "            all_labels.append(edge_labels)\n",
    "            all_preds.append(preds)\n",
    "\n",
    "            loss_recon = binary_recon_loss(z, preds, batch)\n",
    "            loss_kl = kl_loss(mu, logvar)\n",
    "\n",
    "            loss = loss_recon + loss_kl\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_loss_recon += loss_recon.item()\n",
    "            total_loss_kl += loss_kl.item()\n",
    "\n",
    "    y_scores = torch.cat(all_preds)\n",
    "    y_true = torch.cat(all_labels)\n",
    "    auc = compute_auc(y_scores, y_true)\n",
    "    avg_precision = compute_average_precision(y_scores, y_true)\n",
    "    return { \"total_loss\": total_loss, \n",
    "             \"total_loss_recon\": total_loss_recon, \n",
    "             \"total_loss_kl\": total_loss_kl, \n",
    "             \"auc\": auc, \n",
    "             \"average_precision\": avg_precision }\n",
    "\n",
    "@torch.no_grad()\n",
    "def all_evaluate(data, model):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_recon = 0\n",
    "    total_loss_kl = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    data = data.to(device)\n",
    "    z, mu, logvar = model(data)\n",
    "    edge_labels = data[\"user\", \"interacts\", \"item\"].edge_labels\n",
    "    edge_label_index = data[\"user\", \"interacts\", \"item\"].edge_label_index\n",
    "    pos_mask = edge_labels == 1\n",
    "    positive_index = edge_label_index[pos_mask]\n",
    "    negative_index = edge_label_index[~pos_mask]\n",
    "\n",
    "    pos_preds = model.decode(z, positive_index)\n",
    "    neg_preds = model.decode(z, negative_index)\n",
    "\n",
    "    preds = torch.cat([pos_preds, neg_preds])\n",
    "    edge_labels = torch.cat([positive_labels, negative_labels])\n",
    "    all_labels.append(edge_labels)\n",
    "    all_preds.append(preds)\n",
    "\n",
    "    loss_recon = binary_recon_loss(z, preds, data)\n",
    "    loss_kl = kl_loss(mu, logvar)\n",
    "\n",
    "    loss = loss_recon + loss_kl\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    total_loss_recon += loss_recon.item()\n",
    "    total_loss_kl += loss_kl.item()\n",
    "\n",
    "    y_scores = torch.cat(all_preds)\n",
    "    y_true = torch.cat(all_labels)\n",
    "    auc = compute_auc(y_scores, y_true)\n",
    "    avg_precision = compute_average_precision(y_scores, y_true)\n",
    "    return { \"total_loss\": total_loss,\n",
    "            \"total_loss_recon\": total_loss_recon,\n",
    "            \"total_loss_kl\": total_loss_kl,\n",
    "            \"auc\": auc,\n",
    "            \"average_precision\": avg_precision }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gnn_layer_cls = GNN_LAYER_REGISTRY[cfg['gnn_layer_cls']]\n",
    "user_in_channels = train_data[\"user\"].num_features\n",
    "item_in_channels = train_data[\"item\"].num_features\n",
    "\n",
    "## Hyperparameters\n",
    "hidden_channels = cfg['hidden_channels']\n",
    "latent_dim = cfg['latent_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = VGAE(\n",
    "    gnn_layer_cls=GNN_LAYER_REGISTRY[cfg['gnn_layer_cls']],\n",
    "    encoder=VGAEncoder,\n",
    "    decoder=InnerProductDecoder,\n",
    "    user_in_channels=train_data[\"user\"].num_features,\n",
    "    item_in_channels=train_data[\"item\"].num_features,\n",
    "    hidden_channels=cfg['hidden_channels'],\n",
    "    latent_dim=cfg['latent_dim'],\n",
    "    emb_linear_transform=cfg.get('emb_linear_transform', False)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cedfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/3 [00:00<?, ?Epochs/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/3 [06:32<?, ?Epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Epoch 0, Total Loss: 1.6783, Rec. Loss: 1.4924, KL Loss: 0.1860\n",
      "AUC: 0.5130, Average Precision: 0.5057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Average Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# VALIDATION DATA\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m evaluate(\u001b[43mval_loader\u001b[49m, model)\n\u001b[0;32m    103\u001b[0m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    104\u001b[0m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecon_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_loss_recon\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Training loop for your new VGAE version (from cell 17)\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "history = {\n",
    "    \"train\" : defaultdict(list),\n",
    "    \"val\" : defaultdict(list),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "negative_sampler = NegativeSampler(cfg)\n",
    "sampling_strategy = cfg['training'].get('sampling_strategy', 'random')\n",
    "\n",
    "for epoch in trange(epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "    total_loss = 0\n",
    "    total_loss_recon = 0\n",
    "    total_loss_kl = 0\n",
    "    model.train()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        z, mu, logvar = model(batch)\n",
    "\n",
    "\n",
    "        positive_index = batch[\"user\", \"interacts\", \"item\"].edge_label_index\n",
    "        positive_labels = torch.ones(positive_index.size(0), dtype=torch.float32)\n",
    "        if sampling_strategy == \"random\":\n",
    "            negative_index, negative_labels = negative_sampler.random_sample(batch)\n",
    "\n",
    "        pos_preds = model.decode(z, positive_index)\n",
    "        neg_preds = model.decode(z, negative_index)\n",
    "\n",
    "        preds = torch.cat([pos_preds, neg_preds])\n",
    "        edge_labels = torch.cat([positive_labels, negative_labels])\n",
    "\n",
    "        ## Store the prediction\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(edge_labels)\n",
    "\n",
    "        ## Compute the loss\n",
    "        loss_recon = binary_recon_loss(z, preds, batch)\n",
    "        loss_kl = kl_loss(mu, logvar)\n",
    "        loss = loss_recon + loss_kl\n",
    "\n",
    "        # Store the loss\n",
    "        total_loss += loss.item()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(edge_labels)\n",
    "\n",
    "        total_loss_recon += loss_recon.item()\n",
    "        total_loss_kl += loss_kl.item()\n",
    "        \n",
    "        # Loss backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    ## Evaluation\n",
    "    total_loss /= len(train_loader)\n",
    "    total_loss_recon /= len(train_loader)\n",
    "    total_loss_kl /= len(train_loader)\n",
    "    history[\"train\"][\"total_loss\"].append(total_loss)\n",
    "    history[\"train\"][\"recon_loss\"].append(total_loss_recon)\n",
    "    history[\"train\"][\"kl_loss\"].append(total_loss_kl)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        # TRAINING DATA\n",
    "        y_scores, y_true = torch.cat(all_preds), torch.cat(all_labels)\n",
    "        auc_score = compute_auc(y_scores, y_true)\n",
    "        avg_precision = compute_average_precision(y_scores, y_true)\n",
    "        history[\"train\"][\"auc\"].append(auc_score)\n",
    "        history[\"train\"][\"average_precision\"].append(avg_precision)\n",
    "\n",
    "        print(f\"TRAINING DATA\")\n",
    "        print(f\"Epoch {epoch}, Total Loss: {total_loss:.4f}, Rec. Loss: {total_loss_recon:.4f}, KL Loss: {total_loss_kl:.4f}\")\n",
    "        print(f\"AUC: {auc_score:.4f}, Average Precision: {avg_precision:.4f}\")\n",
    "\n",
    "        # VALIDATION DATA\n",
    "        val_metrics = evaluate(val_loader, model)\n",
    "        history[\"val\"][\"total_loss\"].append(val_metrics[\"total_loss\"])\n",
    "        history[\"val\"][\"recon_loss\"].append(val_metrics[\"total_loss_recon\"])\n",
    "        history[\"val\"][\"kl_loss\"].append(val_metrics[\"total_loss_kl\"])\n",
    "        history[\"val\"][\"auc\"].append(val_metrics[\"auc\"])\n",
    "        history[\"val\"][\"average_precision\"].append(val_metrics[\"average_precision\"])\n",
    "\n",
    "        print(f\"VALIDATION DATA\")\n",
    "        print(f\"Epoch {epoch}, Total Loss: {val_metrics['total_loss']:.4f}, Rec. Loss: {val_metrics['total_loss_recon']:.4f}, KL Loss: {val_metrics['total_loss_kl']:.4f}\")\n",
    "        print(f\"AUC: {val_metrics['auc']:.4f}, Average Precision: {val_metrics['average_precision']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77682c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NegativeSampling:\n",
    "#     def __init__(self, num_samples):\n",
    "#         self.num_samples = num_samples\n",
    "\n",
    "#     def sample(self, pos_edge_index, num_nodes):\n",
    "#         neg_src = torch.randint(0, num_nodes, (self.num_samples,))\n",
    "#         neg_dst = torch.randint(0, num_nodes, (self.num_samples,))\n",
    "#         neg_edge_index = torch.stack([neg_src, neg_dst], dim=0)\n",
    "#         return neg_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d1f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e56305",
   "metadata": {
    "id": "c6e56305"
   },
   "outputs": [],
   "source": [
    "class HybridBPRRatingAutoencoder(nn.Module):\n",
    "    def __init__(self, num_features_u, num_features_v, hidden_dim, latent_dim, rating_range=(1, 5)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rating_min, self.rating_max = rating_range\n",
    "\n",
    "        # Encoders (same as before)\n",
    "        self.encoder_u = nn.Sequential(\n",
    "            GCNConv(num_features_u, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            GCNConv(hidden_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "        self.encoder_v = nn.Sequential(\n",
    "            GCNConv(num_features_v, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            GCNConv(hidden_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "        # Rating prediction head\n",
    "        self.rating_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x_u, x_v, edge_index):\n",
    "        z_u = self.encoder_u(x_u, edge_index)\n",
    "        z_v = self.encoder_v(x_v, edge_index)\n",
    "        return z_u, z_v\n",
    "\n",
    "    def predict_score(self, z_u, z_v, user_ids, item_ids):\n",
    "        \"\"\"For BPR ranking\"\"\"\n",
    "        user_emb = z_u[user_ids]\n",
    "        item_emb = z_v[item_ids]\n",
    "        return torch.sum(user_emb * item_emb, dim=1)\n",
    "\n",
    "    def predict_rating(self, z_u, z_v, user_ids, item_ids):\n",
    "        \"\"\"For explicit rating prediction\"\"\"\n",
    "        user_emb = z_u[user_ids]\n",
    "        item_emb = z_v[item_ids]\n",
    "        edge_embeddings = torch.cat([user_emb, item_emb], dim=1)\n",
    "\n",
    "        raw_ratings = self.rating_decoder(edge_embeddings)\n",
    "        ratings = raw_ratings * (self.rating_max - self.rating_min) + self.rating_min\n",
    "\n",
    "        return ratings.squeeze()\n",
    "\n",
    "    def forward(self, x_u, x_v, edge_index):\n",
    "        z_u, z_v = self.encode(x_u, x_v, edge_index)\n",
    "        return z_u, z_v\n",
    "\n",
    "def hybrid_loss(model, z_u, z_v,\n",
    "                # For explicit ratings\n",
    "                rating_user_ids, rating_item_ids, true_ratings, rating_mask,\n",
    "                # For BPR\n",
    "                bpr_user_ids, bpr_pos_items, bpr_neg_items,\n",
    "                rating_weight=1.0, bpr_weight=0.1):\n",
    "    \"\"\"\n",
    "    Combines rating prediction loss and BPR loss\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "\n",
    "    # Rating loss (only on observed ratings)\n",
    "    if rating_mask.sum() > 0:\n",
    "        observed_idx = rating_mask.bool()\n",
    "        pred_ratings = model.predict_rating(z_u, z_v,\n",
    "                                           rating_user_ids[observed_idx],\n",
    "                                           rating_item_ids[observed_idx])\n",
    "        rating_loss = F.mse_loss(pred_ratings, true_ratings[observed_idx])\n",
    "        total_loss += rating_weight * rating_loss\n",
    "\n",
    "    # BPR loss for ranking\n",
    "    if len(bpr_user_ids) > 0:\n",
    "        bpr_loss_val = bpr_loss(model, z_u, z_v, bpr_user_ids, bpr_pos_items, bpr_neg_items)\n",
    "        total_loss += bpr_weight * bpr_loss_val\n",
    "\n",
    "    return total_loss"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
