09-02 20:38:43 - INFO - __main__ - Configuration:
09-02 20:38:43 - INFO - __main__ - {'batch_method': 'binary_link_neighbors',
 'batch_norm': False,
 'batch_size': 64,
 'book_features': [{'dim': 64, 'name': 'random', 'xavier_init': True}],
 'books_filename': 'books_filtered.parquet',
 'coreness_k': 10,
 'decoder': 'inner_product_decoder',
 'descriptions_filename': 'descriptions_filtered.parquet',
 'dir': './data_sample',
 'disjoint_train_ratio': 0.0,
 'dropout': 0.3,
 'emb_linear_transform': False,
 'embeddings_descriptions_filename': 'embeddings_descriptions_sbert_pt.parquet',
 'embeddings_reviews_filename': 'embeddings_reviews_sbert_pt.parquet',
 'encoder': 'vgae_encoder',
 'epochs': 10,
 'eval_interval': 1,
 'gnn_layer_cls': 'gat_conv',
 'hidden_channels': 32,
 'interactions_filename': 'interactions.parquet',
 'language_filter': True,
 'latent_dim': 16,
 'learning_rate': 0.01,
 'n_heads': 5,
 'n_layer': 2,
 'negative_sampling_method': 'batch_random',
 'negative_sampling_ratio': 100.0,
 'num_neighbors': [20, 10],
 'patience': 50,
 'recon_loss': 'binary',
 'review_coreness_k': 5,
 'reviews_filename': 'reviews_filtered.parquet',
 'save_model': True,
 'seed': 42,
 'skip_connection': False,
 'test_size': 0.1,
 'user_features': [{'dim': 64, 'name': 'random', 'xavier_init': True}],
 'users_filename': 'users_filtered.parquet',
 'val_size': 0.1,
 'weight_decay': 1e-05}
09-02 20:38:44 - INFO - src.data_loader - Initial size. Users: 43807, Books: 236065, Total: 279872, Edges: 1134132, Density: 0.010967%
09-02 20:38:44 - INFO - src.data_loader - Filtered size. Users: 1494, Books: 1373, Total: 2867, Edges: 72538, Density: 3.536262%
09-02 20:38:44 - INFO - src.data_loader - Initial textual embeddings size. Descriptions: 1373, Reviews: 17932, Total: 19305
09-02 20:38:44 - INFO - src.data_loader - Filtered textual embeddings size. Descriptions: 1373, Reviews: 17132, Total: 18505
09-02 20:38:44 - DEBUG - __main__ - Train: HeteroData(
  user={ x=[1494, 64] },
  item={ x=[1373, 64] },
  (user, interacts, item)={
    edge_index=[2, 58032],
    edge_label=[58032],
    edge_label_index=[2, 58032],
  },
  (item, rev_interacts, user)={ edge_index=[2, 58032] }
)
09-02 20:38:44 - DEBUG - __main__ - Val: HeteroData(
  user={ x=[1494, 64] },
  item={ x=[1373, 64] },
  (user, interacts, item)={
    edge_index=[2, 58032],
    edge_label=[14506],
    edge_label_index=[2, 14506],
  },
  (item, rev_interacts, user)={ edge_index=[2, 58032] }
)
09-02 20:38:44 - DEBUG - __main__ - Test: HeteroData(
  user={ x=[1494, 64] },
  item={ x=[1373, 64] },
  (user, interacts, item)={
    edge_index=[2, 65285],
    edge_label=[14506],
    edge_label_index=[2, 14506],
  },
  (item, rev_interacts, user)={ edge_index=[2, 65285] }
)
09-02 20:38:44 - DEBUG - root - Inferred 'filter_per_worker=True' option for feature fetching routines of the data loader
09-02 20:38:45 - INFO - model - Model Summary:
09-02 20:38:45 - INFO - model - ----------------
09-02 20:38:45 - INFO - model - Encoder:
09-02 20:38:45 - INFO - model - VGAEncoder(
  (convs): ModuleList(
    (0): GATConv(64, 32, heads=5)
    (1): GATConv(32, 32, heads=5)
  )
  (linears): ModuleList(
    (0-1): 2 x Linear(in_features=160, out_features=32, bias=True)
  )
  (conv_mu): GATConv(32, 16, heads=1)
  (conv_logvar): GATConv(32, 16, heads=1)
)
09-02 20:38:45 - INFO - model - Decoder:
09-02 20:38:45 - INFO - model - InnerProductDecoder()
09-02 20:39:12 - INFO - __main__ - Epoch: 0, Loss: 1.60
09-02 20:39:12 - INFO - __main__ - Train. Total Loss: 1.60, Rec.: 1.46, KL: 0.14, AUC: 50.42%, AP: 1.75%
09-02 20:39:12 - INFO - __main__ - Val. Total Loss: 1.79, Rec.: 1.55, KL: 0.24, AUC: 49.90%, AP: 50.55%
09-02 20:39:38 - INFO - __main__ - Epoch: 1, Loss: 1.53
09-02 20:39:38 - INFO - __main__ - Train. Total Loss: 1.53, Rec.: 1.43, KL: 0.10, AUC: 50.61%, AP: 1.83%
09-02 20:39:38 - INFO - __main__ - Val. Total Loss: 1.77, Rec.: 1.52, KL: 0.25, AUC: 50.37%, AP: 51.00%
09-02 20:40:04 - INFO - __main__ - Epoch: 2, Loss: 1.52
09-02 20:40:04 - INFO - __main__ - Train. Total Loss: 1.52, Rec.: 1.43, KL: 0.09, AUC: 50.57%, AP: 1.82%
09-02 20:40:04 - INFO - __main__ - Val. Total Loss: 1.79, Rec.: 1.57, KL: 0.22, AUC: 50.16%, AP: 51.08%
09-02 20:40:30 - INFO - __main__ - Epoch: 3, Loss: 1.51
09-02 20:40:30 - INFO - __main__ - Train. Total Loss: 1.51, Rec.: 1.43, KL: 0.09, AUC: 50.73%, AP: 1.82%
09-02 20:40:30 - INFO - __main__ - Val. Total Loss: 1.97, Rec.: 1.85, KL: 0.12, AUC: 50.05%, AP: 50.29%
09-02 20:40:57 - INFO - __main__ - Epoch: 4, Loss: nan
09-02 20:40:57 - INFO - __main__ - Train. Total Loss: nan, Rec.: nan, KL: nan, AUC: 50.04%, AP: 1.78%
09-02 20:40:57 - INFO - __main__ - Val. Total Loss: nan, Rec.: nan, KL: nan, AUC: 100.00%, AP: 100.00%
09-02 20:41:23 - INFO - __main__ - Epoch: 5, Loss: nan
09-02 20:41:23 - INFO - __main__ - Train. Total Loss: nan, Rec.: nan, KL: nan, AUC: 50.04%, AP: 1.79%
09-02 20:41:23 - INFO - __main__ - Val. Total Loss: nan, Rec.: nan, KL: nan, AUC: 100.00%, AP: 100.00%
09-02 20:41:49 - INFO - __main__ - Epoch: 6, Loss: nan
09-02 20:41:49 - INFO - __main__ - Train. Total Loss: nan, Rec.: nan, KL: nan, AUC: 50.04%, AP: 1.79%
09-02 20:41:49 - INFO - __main__ - Val. Total Loss: nan, Rec.: nan, KL: nan, AUC: 100.00%, AP: 100.00%
09-02 20:42:16 - INFO - __main__ - Epoch: 7, Loss: nan
09-02 20:42:16 - INFO - __main__ - Train. Total Loss: nan, Rec.: nan, KL: nan, AUC: 50.03%, AP: 1.79%
09-02 20:42:16 - INFO - __main__ - Val. Total Loss: nan, Rec.: nan, KL: nan, AUC: 100.00%, AP: 100.00%
09-02 20:42:42 - INFO - __main__ - Epoch: 8, Loss: nan
09-02 20:42:42 - INFO - __main__ - Train. Total Loss: nan, Rec.: nan, KL: nan, AUC: 50.04%, AP: 1.79%
09-02 20:42:42 - INFO - __main__ - Val. Total Loss: nan, Rec.: nan, KL: nan, AUC: 100.00%, AP: 100.00%
09-02 20:43:08 - INFO - __main__ - Epoch: 9, Loss: nan
09-02 20:43:08 - INFO - __main__ - Train. Total Loss: nan, Rec.: nan, KL: nan, AUC: 50.00%, AP: 1.79%
09-02 20:43:08 - INFO - __main__ - Val. Total Loss: nan, Rec.: nan, KL: nan, AUC: 100.00%, AP: 100.00%
