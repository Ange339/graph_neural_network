{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aded2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vJMG8gbuQ5g2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25729,
     "status": "ok",
     "timestamp": 1755874642037,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "vJMG8gbuQ5g2",
    "outputId": "ce3cc13e-c2c9-4ae4-ad9b-920d3d1dbce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: igraph in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (0.11.9)\n",
      "Requirement already satisfied: texttable>=1.6.2 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from igraph) (1.7.0)\n",
      "Collecting scikit-network\n",
      "  Downloading scikit_network-0.33.3-cp310-cp310-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from scikit-network) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from scikit-network) (1.15.3)\n",
      "Downloading scikit_network-0.33.3-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 2.1/2.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 9.3 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-network\n",
      "Successfully installed scikit-network-0.33.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install igraph\n",
    "# !pip install scikit-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471eb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torchmetrics) (2.1.0)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (78.1.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (2025.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from sympy->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Downloading torchmetrics-1.8.1-py3-none-any.whl (982 kB)\n",
      "   ---------------------------------------- 0.0/983.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 983.0/983.0 kB 48.1 MB/s  0:00:00\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "\n",
      "   ---------------------------------------- 0/2 [lightning-utilities]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   -------------------- ------------------- 1/2 [torchmetrics]\n",
      "   ---------------------------------------- 2/2 [torchmetrics]\n",
      "\n",
      "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!conda install pytorch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 2.1.0\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import os\n",
    "# print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "\n",
    "# srs_url = f\"https://pytorch-geometric.com/whl/torch-{torch.__version__}.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3843554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
      "Collecting torch_scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_scatter-2.1.2%2Bpt21cpu-cp310-cp310-win_amd64.whl (336 kB)\n",
      "Installing collected packages: torch_scatter\n",
      "Successfully installed torch_scatter-2.1.2+pt21cpu\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
      "Collecting torch_sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_sparse-0.6.18%2Bpt21cpu-cp310-cp310-win_amd64.whl (788 kB)\n",
      "     ---------------------------------------- 0.0/788.9 kB ? eta -:--:--\n",
      "     ------------------------------------- 788.9/788.9 kB 17.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch_sparse) (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from scipy->torch_sparse) (2.0.1)\n",
      "Installing collected packages: torch_sparse\n",
      "Successfully installed torch_sparse-0.6.18+pt21cpu\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
      "Collecting torch_cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_cluster-1.6.3%2Bpt21cpu-cp310-cp310-win_amd64.whl (506 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch_cluster) (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from scipy->torch_cluster) (2.0.1)\n",
      "Installing collected packages: torch_cluster\n",
      "Successfully installed torch_cluster-1.6.3+pt21cpu\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
      "Collecting torch_spline_conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt21cpu-cp310-cp310-win_amd64.whl (177 kB)\n",
      "Installing collected packages: torch_spline_conv\n",
      "Successfully installed torch_spline_conv-1.2.2+pt21cpu\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch_scatter -f $srs_url\n",
    "# !pip install torch_sparse -f $srs_url\n",
    "# !pip install torch_cluster -f $srs_url\n",
    "# !pip install torch_spline_conv -f $srs_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c07ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting fsspec (from torch_geometric)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch_geometric) (2.0.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch_geometric) (7.0.0)\n",
      "Collecting pyparsing (from torch_geometric)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from torch_geometric) (2.32.4)\n",
      "Collecting tqdm (from torch_geometric)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch_geometric)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->torch_geometric)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch_geometric)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading multidict-6.6.4-cp310-cp310-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from requests->torch_geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from requests->torch_geometric) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\angel\\anaconda3\\envs\\pyg\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Downloading aiohttp-3.12.15-cp310-cp310-win_amd64.whl (452 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.4-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, pyparsing, propcache, multidict, fsspec, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch_geometric\n",
      "\n",
      "   ----------------------------------------  0/13 [tqdm]\n",
      "   ------ ---------------------------------  2/13 [propcache]\n",
      "   ------------ ---------------------------  4/13 [fsspec]\n",
      "   ------------ ---------------------------  4/13 [fsspec]\n",
      "   --------------- ------------------------  5/13 [frozenlist]\n",
      "   --------------------- ------------------  7/13 [async-timeout]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ------------------------------------ --- 12/13 [torch_geometric]\n",
      "   ---------------------------------------- 13/13 [torch_geometric]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.3.0 frozenlist-1.7.0 fsspec-2025.7.0 multidict-6.6.4 propcache-0.3.2 pyparsing-3.2.3 torch_geometric-2.6.1 tqdm-4.67.1 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Voe3ED3WRFsV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53284,
     "status": "ok",
     "timestamp": 1755874695512,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "Voe3ED3WRFsV",
    "outputId": "9b8f371c-ce89-4da5-9165-484c8e266a9f"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import os\n",
    "# print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#   !pip install torch==2.4.0\n",
    "\n",
    "# # Install torch geometric\n",
    "# if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "#   torch_version = str(torch.__version__)\n",
    "#   scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "#   sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "#   !pip install torch-scatter -f $scatter_src\n",
    "#   !pip install torch-sparse -f $sparse_src\n",
    "#   !pip install torch-geometric\n",
    "#   !pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e675cc97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3286,
     "status": "ok",
     "timestamp": 1755874723445,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "e675cc97",
    "outputId": "7634e6dd-140e-4f9e-dcf4-2a361ca3547c"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import scipy.sparse as sp\n",
    "from typing import Literal\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "#%env NX_CUGRAPH_AUTOCONFIG=True\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite, community\n",
    "nx.config.warnings_to_ignore.add(\"cache\")\n",
    "\n",
    "import igraph as ig\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, VGAE, to_hetero\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler  import NegativeSampling\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0ebafd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6350,
     "status": "ok",
     "timestamp": 1755874761333,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "fb0ebafd",
    "outputId": "9db560c5-0716-482c-bc7f-3c346b148512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 39536, Books: 111119, Total: 150655, Edges: 1134132\n",
      "Density: 0.0258%\n",
      "Users: 3305, Books: 3799, Total: 7104, Edges: 164377\n",
      "Density: 1.309183%\n"
     ]
    }
   ],
   "source": [
    "review_coreness_k = 3\n",
    "\n",
    "g = ig.read(\"data_sample/graph.graphml\")\n",
    "\n",
    "users = len(g.vs.select(type_eq = 0))\n",
    "books = len(g.vs.select(type_eq = 1))\n",
    "print(f\"Users: {users}, Books: {books}, Total: {users + books}, Edges: {len(g.es)}\")\n",
    "print(f\"Density: {len(g.es) / (users*books):.4%}\")\n",
    "\n",
    "## Condition filtering\n",
    "\n",
    "subg = g.subgraph(g.vs.select(review_coreness_ge = review_coreness_k))\n",
    "\n",
    "users = len(subg.vs.select(type_eq = 0))\n",
    "books = len(subg.vs.select(type_eq = 1))\n",
    "\n",
    "print(f\"Users: {users}, Books: {books}, Total: {users + books}, Edges: {len(subg.es)}\")\n",
    "print(f\"Density: {len(subg.es) / (users*books):4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41e6e85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1755874761792,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "f41e6e85",
    "outputId": "3da489ee-72d6-40c2-f02c-3e0a3a5c38ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[3305, 1] },\n",
      "  item={ x=[3799, 1] },\n",
      "  (user, interacts, item)={ edge_index=[2, 164377] },\n",
      "  (item, rev_interacts, user)={ edge_index=[2, 164377] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def igraph_to_hetero_pyg(g, user_type=0, book_type=1, user_node_type='user', item_node_type='item', edge_type='interacts'):\n",
    "    \"\"\"\n",
    "    Convert an igraph bipartite graph to a PyG HeteroData object.\n",
    "    Assumes:\n",
    "      - Vertex attribute 'type' distinguishes users (user_type) and books (book_type)\n",
    "      - Edges are user->book (bipartite)\n",
    "    \"\"\"\n",
    "    # Map igraph node indices to user/item indices\n",
    "    user_indices = [v.index for v in g.vs if v['type'] == user_type]\n",
    "    book_indices = [v.index for v in g.vs if v['type'] == book_type]\n",
    "    user_map = {idx: i for i, idx in enumerate(user_indices)}\n",
    "    book_map = {idx: i for i, idx in enumerate(book_indices)}\n",
    "\n",
    "    # Node features (optional: here just zeros)\n",
    "    user_x = torch.zeros((len(user_indices), 1), dtype=torch.float)\n",
    "    book_x = torch.zeros((len(book_indices), 1), dtype=torch.float)\n",
    "\n",
    "    # Edges: only user->book\n",
    "    src, dst = [], []\n",
    "    for e in g.es:\n",
    "        s, t = e.source, e.target\n",
    "        if g.vs[s]['type'] == user_type and g.vs[t]['type'] == book_type:\n",
    "            src.append(user_map[s])\n",
    "            dst.append(book_map[t])\n",
    "    edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "    data = HeteroData()\n",
    "    data[user_node_type].x = user_x\n",
    "    data[item_node_type].x = book_x\n",
    "    data[(user_node_type, edge_type, item_node_type)].edge_index = edge_index\n",
    "    data = T.ToUndirected()(data) # Convert to undirected\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "data = igraph_to_hetero_pyg(subg)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebb66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_node_feature_embedding(data, hidden_channel):\n",
    "    user_embedding = nn.Embedding(data[\"user\"].num_nodes, hidden_channel)\n",
    "    item_embedding = nn.Embedding(data[\"item\"].num_nodes, hidden_channel)\n",
    "    return user_embedding, item_embedding\n",
    "\n",
    "hidden_channel = 64\n",
    "\n",
    "user_embedding, item_embedding = random_node_feature_embedding(data, hidden_channel)\n",
    "\n",
    "data['user'].x = user_embedding.weight\n",
    "data['item'].x = item_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f56d3b",
   "metadata": {
    "id": "68f56d3b",
    "outputId": "fe11545f-55c2-46aa-ba5d-1899ac4b5214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[150655, 5], edge_index=[2, 1134132], edge_attr=[1134132, 1])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from torch_geometric.data import Data\n",
    "# import xml.etree.ElementTree as ET\n",
    "\n",
    "# def read_graphml_to_hetero_pyg(path, user_prefix=\"u\", item_prefix=\"i\"):\n",
    "#     tree = ET.parse(path)\n",
    "#     root = tree.getroot()\n",
    "#     ns = {'g': 'http://graphml.graphdrawing.org/xmlns'}\n",
    "\n",
    "#     key_map = {}\n",
    "#     for key in root.findall('g:key', ns):\n",
    "#         key_id = key.attrib['id']\n",
    "#         key_map[key_id] = key.attrib.get('attr.name', key_id)\n",
    "\n",
    "#     # Separate users and items by prefix\n",
    "#     user_map, item_map = {}, {}\n",
    "#     user_features, item_features = [], []\n",
    "#     for idx, node in enumerate(root.findall('.//g:node', ns)):\n",
    "#         node_id = node.attrib['id']\n",
    "#         feat = []\n",
    "#         for data in node.findall('g:data', ns):\n",
    "#             value = data.text\n",
    "#             try:\n",
    "#                 feat.append(float(value))\n",
    "#             except (ValueError, TypeError):\n",
    "#                 pass\n",
    "#         feat = feat or [0.0]\n",
    "#         if node_id.startswith(user_prefix):\n",
    "#             user_map[node_id] = len(user_map)\n",
    "#             user_features.append(feat)\n",
    "#         elif node_id.startswith(item_prefix):\n",
    "#             item_map[node_id] = len(item_map)\n",
    "#             item_features.append(feat)\n",
    "\n",
    "#     # Edges: from users to items\n",
    "#     edge_index = [[], []]\n",
    "#     edge_attrs = []\n",
    "#     for edge in root.findall('.//g:edge', ns):\n",
    "#         src_id = edge.attrib['source']\n",
    "#         tgt_id = edge.attrib['target']\n",
    "#         # Only keep user->item edges\n",
    "#         if src_id in user_map and tgt_id in item_map:\n",
    "#             src = user_map[src_id]\n",
    "#             tgt = item_map[tgt_id]\n",
    "#             edge_index[0].append(src)\n",
    "#             edge_index[1].append(tgt)\n",
    "#             feat = []\n",
    "#             for data in edge.findall('g:data', ns):\n",
    "#                 value = data.text\n",
    "#                 try:\n",
    "#                     feat.append(float(value))\n",
    "#                 except (ValueError, TypeError):\n",
    "#                     pass\n",
    "#             edge_attrs.append(feat or [0.0])\n",
    "\n",
    "#     # Convert to tensors\n",
    "#     user_x = torch.tensor(user_features, dtype=torch.float) if user_features else torch.empty((0, 1))\n",
    "#     item_x = torch.tensor(item_features, dtype=torch.float) if item_features else torch.empty((0, 1))\n",
    "#     edge_index = torch.tensor(edge_index, dtype=torch.long) if edge_index[0] else torch.empty((2, 0), dtype=torch.long)\n",
    "#     edge_attr = torch.tensor(edge_attrs, dtype=torch.float) if edge_attrs else torch.empty((0, 1))\n",
    "\n",
    "#     data = HeteroData()\n",
    "#     data['user'].x = user_x\n",
    "#     data['book'].x = item_x\n",
    "#     data['user', 'interacts', 'book'].edge_index = edge_index\n",
    "#     data['user', 'interacts', 'book'].edge_attr = edge_attr\n",
    "#     return data\n",
    "\n",
    "# # Example usage\n",
    "# DIR = 'data_sample'\n",
    "# data = read_graphml_to_pyg(os.path.join(DIR, \"graph.graphml\"))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e485a421",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 186,
     "status": "ok",
     "timestamp": 1755874770394,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "e485a421",
    "outputId": "b05f6b9d-9b8c-44c4-8036-5821e8797d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "==============\n",
      "HeteroData(\n",
      "  user={ x=[3305, 64] },\n",
      "  item={ x=[3799, 64] },\n",
      "  (user, interacts, item)={\n",
      "    edge_index=[2, 131503],\n",
      "    edge_label=[131503],\n",
      "    edge_label_index=[2, 131503],\n",
      "  },\n",
      "  (item, rev_interacts, user)={ edge_index=[2, 131503] }\n",
      ")\n",
      "\n",
      "Validation data:\n",
      "================\n",
      "HeteroData(\n",
      "  user={ x=[3305, 64] },\n",
      "  item={ x=[3799, 64] },\n",
      "  (user, interacts, item)={\n",
      "    edge_index=[2, 131503],\n",
      "    edge_label=[49311],\n",
      "    edge_label_index=[2, 49311],\n",
      "  },\n",
      "  (item, rev_interacts, user)={ edge_index=[2, 131503] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## edge_index : edges used for the message passing\n",
    "## edge_label : edges used for the supervised learning task.\n",
    "## Some edges in edge_label_index might be in edge_index, as they might be used for supervision and message passing\n",
    "\n",
    "# % of edges used for supervision that are not in the message passing (theoretically)\n",
    "disjoint_train_ratio = 0.0 # We set it zero for transductive learning\n",
    "\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=disjoint_train_ratio, \n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"user\", \"interacts\", \"item\"),\n",
    "    rev_edge_types=(\"item\", \"rev_interacts\", \"user\"),\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(\"Training data:\")\n",
    "print(\"==============\")\n",
    "print(train_data)\n",
    "print()\n",
    "print(\"Validation data:\")\n",
    "print(\"================\")\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76877c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Overlapping edges found between edge_index and edge_label_index\n",
      "Overlapping edges size: 131503\n"
     ]
    }
   ],
   "source": [
    "def validate_edge_indices(data):\n",
    "    all_index = set()\n",
    "    edge_index = data[\"user\", \"interacts\", \"item\"].edge_index\n",
    "    for u, v in zip(edge_index[0], edge_index[1]):\n",
    "        all_index.add((u.item(), v.item()))\n",
    "    \n",
    "    all_label_index = set()\n",
    "    edge_label_index = data[\"user\", \"interacts\", \"item\"].edge_label_index\n",
    "    for u, v in zip(edge_label_index[0], edge_label_index[1]):\n",
    "        all_label_index.add((u.item(), v.item()))\n",
    "\n",
    "    assert len(all_index) == len(edge_index[0])\n",
    "    assert len(all_label_index) == len(edge_label_index[0])\n",
    "\n",
    "    intersection = all_index.intersection(all_label_index)\n",
    "    \n",
    "\n",
    "    if len(intersection) > 0:\n",
    "        print(f\"Warning: Overlapping edges found between edge_index and edge_label_index\")\n",
    "        print(f\"Overlapping edges size: {len(intersection)}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "validate_edge_indices(train_data)\n",
    "validate_edge_indices(val_data)\n",
    "validate_edge_indices(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "906be191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 612, 1065,    8,  ...,  603, 1608, 2245],\n",
       "        [2017, 3440, 1608,  ..., 3726, 3680,  343]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"user\", \"interacts\", \"item\"].edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f472c1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "error",
     "timestamp": 1755874773128,
     "user": {
      "displayName": "angelo cao",
      "userId": "13059316039091548203"
     },
     "user_tz": -120
    },
    "id": "8f472c1b",
    "outputId": "a6f92989-8db3-4ee4-be17-b4966487708d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled mini-batch:\n",
      "===================\n",
      "HeteroData(\n",
      "  user={\n",
      "    x=[2803, 64],\n",
      "    n_id=[2803],\n",
      "  },\n",
      "  item={\n",
      "    x=[3018, 64],\n",
      "    n_id=[3018],\n",
      "  },\n",
      "  (user, interacts, item)={\n",
      "    edge_index=[2, 13499],\n",
      "    edge_label=[128],\n",
      "    edge_label_index=[2, 128],\n",
      "    e_id=[13499],\n",
      "    input_id=[64],\n",
      "  },\n",
      "  (item, rev_interacts, user)={\n",
      "    edge_index=[2, 14228],\n",
      "    e_id=[14228],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "num_negative_sampling_ratio = 1.0\n",
    "\n",
    "# Define seed edges:\n",
    "edge_label_index = train_data[\"user\", \"interacts\", \"item\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"interacts\", \"item\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    edge_label_index=((\"user\", \"interacts\", \"item\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=batch_size,\n",
    "    neg_sampling=NegativeSampling(mode='binary', amount=num_negative_sampling_ratio), # Let's first use the default option, we will improve it later if needed\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)\n",
    "\n",
    "assert sampled_data[\"user\", \"interacts\", \"item\"].edge_label_index.size(1) == (num_negative_sampling_ratio + 1) * batch_size\n",
    "assert sampled_data[\"user\", \"interacts\", \"item\"].edge_label.min() == 0\n",
    "assert sampled_data[\"user\", \"interacts\", \"item\"].edge_label.max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder, \n",
    "                 decoder,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        gnn_layer_cls: class of the GNN layer (e.g., GCNConv, SAGEConv)\n",
    "        encoder_cls: class of the encoder (should accept gnn_layer_cls, in_channels, hidden_channels, latent_dim)\n",
    "        decoder_cls: class of the decoder (should accept no arguments)\n",
    "        in_channels: input feature dimension\n",
    "        hidden_channels: hidden layer dimension\n",
    "        latent_dim: latent space dimension\n",
    "        encoder_kwargs: additional kwargs for encoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        mu, logvar = self.encoder(x, edge_index)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return self.decoder(z, edge_index)\n",
    "\n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index):\n",
    "        pos_score = torch.sigmoid(self.decode(z, pos_edge_index))\n",
    "        neg_score = torch.sigmoid(self.decode(z, neg_edge_index))\n",
    "        pos_loss = -torch.log(pos_score + 1e-15).mean()\n",
    "        neg_loss = -torch.log(1 - neg_score + 1e-15).mean()\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def kl_loss(self, mu, logvar):\n",
    "        kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return kl_div\n",
    "\n",
    "class VGAEncoder(nn.Module):\n",
    "    def __init__(self, GNNLayer, in_channels, hidden_channels, latent_dim):\n",
    "        \"\"\"\n",
    "        in_channels: dimension of the node input features (after projecting items and using user embeddings)\n",
    "        hidden_channels: hidden units for first GCN layer\n",
    "        latent_dim: dimension of mu and logvar\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = GNNLayer(in_channels, hidden_channels)\n",
    "        self.conv_mu = GNNLayer(hidden_channels, latent_dim)\n",
    "        self.conv_logvar = GNNLayer(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "        return mu, logvar\n",
    "\n",
    "class InnerProductDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z_user, z_book, edge_index, sigmoid=True):\n",
    "        edge_feat_user = z_user[edge_index[0]]\n",
    "        edge_feat_book = z_book[edge_index[1]]\n",
    "        score = (edge_feat_user * edge_feat_book).sum(dim=-1)\n",
    "        if sigmoid:\n",
    "            score = torch.sigmoid(score)\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdbe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batch training loop using train_loader and sampled_data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate model\n",
    "in_channels = data['user'].x.shape[1]\n",
    "hidden_channels = 32\n",
    "latent_dim = 16\n",
    "\n",
    "encoder = VGAEncoder(GCNConv, in_channels, hidden_channels, latent_dim).to(device)\n",
    "decoder = InnerProductDecoder().to(device)\n",
    "model = VGAE(encoder, decoder).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Mini-batch training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm.tqdm(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        user_x = batch['user'].x\n",
    "        book_x = batch['book'].x\n",
    "        x = torch.cat([user_x, book_x], dim=0)\n",
    "        edge_index = batch['user', 'interacts', 'book'].edge_index\n",
    "\n",
    "        # Encode and decode\n",
    "        z, mu, logvar = model(x, edge_index)\n",
    "\n",
    "        # Use edge_label_index for positive edges, sample negatives\n",
    "        pos_edge_index = batch['user', 'interacts', 'book'].edge_label_index\n",
    "        # Negative sampling: random pairs (for demonstration)\n",
    "        num_neg = pos_edge_index.shape[1]\n",
    "        neg_src = torch.randint(0, x.size(0), (num_neg,), device=device)\n",
    "        neg_dst = torch.randint(0, batch['book'].x.size(0), (num_neg,), device=device)\n",
    "        neg_edge_index = torch.stack([neg_src, neg_dst], dim=0)\n",
    "\n",
    "        # Compute losses\n",
    "        loss_recon = model.recon_loss(z, pos_edge_index, neg_edge_index)\n",
    "        loss_kl = model.kl_loss(mu, logvar)\n",
    "        loss = loss_recon + loss_kl\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac83e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 gnn_layer_cls,\n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 user_in_channels,\n",
    "                 item_in_channels,\n",
    "                 hidden_channels,\n",
    "                 latent_dim,\n",
    "                 emb_linear_transform,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        gnn_layer_cls: class of the GNN layer (e.g., GCNConv, SAGEConv)\n",
    "        encoder_cls: class of the encoder (should accept gnn_layer_cls, in_channels, hidden_channels, latent_dim)\n",
    "        decoder_cls: class of the decoder (should accept no arguments)\n",
    "        in_channels: input feature dimension\n",
    "        hidden_channels: hidden layer dimension\n",
    "        latent_dim: latent space dimension\n",
    "        encoder_kwargs: additional kwargs for encoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.emb_linear_transform = emb_linear_transform\n",
    "        self.user_linear = nn.Linear(user_in_channels, hidden_channels)\n",
    "        self.item_linear = nn.Linear(item_in_channels, hidden_channels)\n",
    "\n",
    "        if user_in_channels != item_in_channels:\n",
    "            print(f\"Inconsistent input feature dimensions: user={user_in_channels}, item={item_in_channels}\")\n",
    "            print(f\"Forcing linear transformation\")\n",
    "            self.emb_linear_transform = True\n",
    "\n",
    "        self.input_channels = hidden_channels if self.emb_linear_transform else user_in_channels\n",
    "\n",
    "        # Random initialization of embeddings, don't use it for now\n",
    "        # self.user_embedding = nn.Embedding(data[user].num_nodes, hidden_channels)\n",
    "        # self.item_embedding = nn.Embedding(data[item].num_nodes, hidden_channels)\n",
    "\n",
    "        self.encoder = encoder(gnn_layer_cls, hidden_channels, hidden_channels, latent_dim)\n",
    "        self.encoder = to_hetero(self.encoder, metadata=data.metadata())\n",
    "        self.decoder = decoder()\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, data):\n",
    "        if self.emb_linear_transform:\n",
    "            x_dict = {\n",
    "                \"user\": self.user_linear(data[\"user\"].x),\n",
    "                \"item\": self.item_linear(data[\"item\"].x)\n",
    "            }\n",
    "        else:\n",
    "            x_dict = {\n",
    "                \"user\": data[\"user\"].x,\n",
    "                \"item\": data[\"item\"].x\n",
    "            }\n",
    "\n",
    "        mu, logvar = self.encoder(x_dict, data.edge_index_dict)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return self.decoder(z, edge_index)\n",
    "\n",
    "    def recon_loss(self, z, pos_edge_index, neg_edge_index):\n",
    "        pos_score = self.decode(z, pos_edge_index)\n",
    "        neg_score = self.decode(z, neg_edge_index)\n",
    "        pos_loss = -torch.log(pos_score + 1e-15).mean()\n",
    "        neg_loss = -torch.log(1 - neg_score + 1e-15).mean()\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def kl_loss(self, mu, logvar):\n",
    "        kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return kl_div\n",
    "\n",
    "class VGAEncoder(nn.Module):\n",
    "    def __init__(self, GNNLayer, in_channels, hidden_channels, latent_dim):\n",
    "        \"\"\"\n",
    "        in_channels: dimension of the node input features (after projecting items and using user embeddings)\n",
    "        hidden_channels: hidden units for first GCN layer\n",
    "        latent_dim: dimension of mu and logvar\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = GNNLayer(in_channels, hidden_channels)\n",
    "        self.conv_mu = GNNLayer(hidden_channels, latent_dim)\n",
    "        self.conv_logvar = GNNLayer(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "        return mu, logvar\n",
    "\n",
    "class InnerProductDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z_user, z_item, edge_index, sigmoid=True):\n",
    "        edge_feat_user = z_user[edge_index[0]]\n",
    "        edge_feat_item = z_item[edge_index[1]]\n",
    "        score = (edge_feat_user * edge_feat_item).sum(dim=-1)\n",
    "        if sigmoid:\n",
    "            score = torch.sigmoid(score)\n",
    "        return score\n",
    "\n",
    "    def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f9ab44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 gnn_layer_cls,\n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 user_in_channels,\n",
    "                 item_in_channels,\n",
    "                 hidden_channels,\n",
    "                 latent_dim,\n",
    "                 emb_linear_transform,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        gnn_layer_cls: class of the GNN layer (e.g., GCNConv, SAGEConv)\n",
    "        encoder_cls: class of the encoder (should accept gnn_layer_cls, in_channels, hidden_channels, latent_dim)\n",
    "        decoder_cls: class of the decoder (should accept no arguments)\n",
    "        in_channels: input feature dimension\n",
    "        hidden_channels: hidden layer dimension\n",
    "        latent_dim: latent space dimension\n",
    "        encoder_kwargs: additional kwargs for encoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.emb_linear_transform = emb_linear_transform\n",
    "        self.user_linear = nn.Linear(user_in_channels, hidden_channels)\n",
    "        self.item_linear = nn.Linear(item_in_channels, hidden_channels)\n",
    "\n",
    "        if user_in_channels != item_in_channels:\n",
    "            print(f\"Inconsistent input feature dimensions: user={user_in_channels}, item={item_in_channels}\")\n",
    "            print(f\"Forcing linear transformation\")\n",
    "            self.emb_linear_transform = True\n",
    "\n",
    "        input_channels = hidden_channels if self.emb_linear_transform else user_in_channels\n",
    "\n",
    "        # Random initialization of embeddings, don't use it for now\n",
    "        # self.user_embedding = nn.Embedding(data[user].num_nodes, hidden_channels)\n",
    "        # self.item_embedding = nn.Embedding(data[item].num_nodes, hidden_channels)\n",
    "\n",
    "        self.encoder = encoder(gnn_layer_cls, input_channels, hidden_channels, latent_dim)\n",
    "        self.decoder = decoder()\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, data):\n",
    "        if self.emb_linear_transform:\n",
    "            user_x = self.user_linear(data[\"user\"].x)\n",
    "            item_x = self.item_linear(data[\"item\"].x)\n",
    "        else:\n",
    "            user_x = data[\"user\"].x\n",
    "            item_x = data[\"item\"].x\n",
    "\n",
    "        x = torch.cat([user_x, item_x], dim=0)\n",
    "        edge_index = data['user', 'interacts', 'item'].edge_index\n",
    "\n",
    "        mu, logvar = self.encoder(x, edge_index)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return self.decoder(z, edge_index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class VGAEncoder(nn.Module):\n",
    "    def __init__(self, GNNLayer, in_channels, hidden_channels, latent_dim):\n",
    "        \"\"\"\n",
    "        in_channels: dimension of the node input features (after projecting items and using user embeddings)\n",
    "        hidden_channels: hidden units for first GCN layer\n",
    "        latent_dim: dimension of mu and logvar\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = GNNLayer(in_channels, hidden_channels)\n",
    "        self.conv_mu = GNNLayer(hidden_channels, latent_dim)\n",
    "        self.conv_logvar = GNNLayer(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "class InnerProductDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "        edge_feat_user = z[edge_index[0]]\n",
    "        edge_feat_item = z[edge_index[1]]\n",
    "        score = (edge_feat_user * edge_feat_item).sum(dim=-1)\n",
    "        if sigmoid:\n",
    "            score = torch.sigmoid(score)\n",
    "        return score\n",
    "    \n",
    "    def forward_all(self, z, sigmoid=True):\n",
    "        \"Use it cautiously, as it computes all pairwise interactions\"\n",
    "        A_pred = (z @ z.T).view(-1)\n",
    "        if sigmoid:\n",
    "            A_pred = torch.sigmoid(A_pred)\n",
    "        return A_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b581173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binary_recon_loss(z, preds, batch):\n",
    "    edge_labels = batch[\"user\", \"interacts\", \"item\"].edge_label\n",
    "    pos_mask = edge_labels == 1\n",
    "    pos_score = preds[pos_mask]\n",
    "    neg_score = preds[~pos_mask]\n",
    "\n",
    "    pos_loss = -torch.log(pos_score + 1e-15).mean()\n",
    "    neg_loss = -torch.log(1 - neg_score + 1e-15).mean()\n",
    "\n",
    "    return pos_loss + neg_loss\n",
    "\n",
    "def kl_loss(mu, logvar):\n",
    "    kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdbc2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import AveragePrecision, AUROC\n",
    "\n",
    "def compute_auc(y_scores, y_true):\n",
    "    y_true = y_true.long() \n",
    "    score = AUROC(task=\"binary\")(y_scores, y_true).item()\n",
    "    return score\n",
    "\n",
    "def compute_average_precision(y_scores, y_true):\n",
    "    y_true = y_true.long() \n",
    "    score = AveragePrecision(task=\"binary\")(y_scores, y_true).item()\n",
    "    return score\n",
    "\n",
    "def evaluate(loader, model):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_recon = 0\n",
    "    total_loss_kl = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            z, mu, logvar = model(batch)\n",
    "            edge_labels = batch[\"user\", \"interacts\", \"item\"].edge_label\n",
    "            edge_index = batch[\"user\", \"interacts\", \"item\"].edge_label_index\n",
    "            preds = model.decode(z, edge_index)\n",
    "            all_labels.append(edge_labels)\n",
    "            all_preds.append(preds)\n",
    "\n",
    "            loss_recon = binary_recon_loss(z, preds, batch)\n",
    "            loss_kl = kl_loss(mu, logvar)\n",
    "\n",
    "            loss = loss_recon + loss_kl\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_loss_recon += loss_recon.item()\n",
    "            total_loss_kl += loss_kl.item()\n",
    "\n",
    "    y_scores = torch.cat(all_preds)\n",
    "    y_true = torch.cat(all_labels)\n",
    "    auc = compute_auc(y_scores, y_true)\n",
    "    avg_precision = compute_average_precision(y_scores, y_true)\n",
    "    return { \"total_loss\": total_loss, \n",
    "             \"total_loss_recon\": total_loss_recon, \n",
    "             \"total_loss_kl\": total_loss_kl, \n",
    "             \"auc\": auc, \n",
    "             \"average_precision\": avg_precision }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "438cedfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/3 [00:00<?, ?Epochs/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/3 [06:32<?, ?Epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Epoch 0, Total Loss: 1.6783, Rec. Loss: 1.4924, KL Loss: 0.1860\n",
      "AUC: 0.5130, Average Precision: 0.5057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Average Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# VALIDATION DATA\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m evaluate(\u001b[43mval_loader\u001b[49m, model)\n\u001b[0;32m    103\u001b[0m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    104\u001b[0m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecon_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_loss_recon\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Training loop for your new VGAE version (from cell 17)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "gnn_layer_cls = GCNConv\n",
    "user_in_channels = train_data[\"user\"].num_features\n",
    "item_in_channels = train_data[\"item\"].num_features\n",
    "\n",
    "## Hyperparameters\n",
    "hidden_channels = 32\n",
    "latent_dim = 16\n",
    "\n",
    "# Instantiate model\n",
    "model = VGAE(\n",
    "    gnn_layer_cls=gnn_layer_cls,\n",
    "    encoder=VGAEncoder,\n",
    "    decoder=InnerProductDecoder,\n",
    "    user_in_channels=user_in_channels,\n",
    "    item_in_channels=item_in_channels,\n",
    "    hidden_channels=hidden_channels,\n",
    "    latent_dim=latent_dim,\n",
    "    emb_linear_transform=False\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "history = {\n",
    "    \"train\" : defaultdict(list),\n",
    "    \"val\" : defaultdict(list),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in trange(epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "    total_loss = 0\n",
    "    total_loss_recon = 0\n",
    "    total_loss_kl = 0\n",
    "    model.train()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        z, mu, logvar = model(batch)\n",
    "        edge_index = batch[\"user\", \"interacts\", \"item\"].edge_label_index\n",
    "        edge_labels = batch[\"user\", \"interacts\", \"item\"].edge_label\n",
    "        preds = model.decode(z, edge_index)\n",
    "\n",
    "        ## Store the prediction\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(edge_labels)\n",
    "\n",
    "        ## Compute the loss\n",
    "        loss_recon = binary_recon_loss(z, preds, batch)\n",
    "        loss_kl = kl_loss(mu, logvar)\n",
    "        loss = loss_recon + loss_kl\n",
    "\n",
    "        # Store the loss\n",
    "        total_loss += loss.item()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(edge_labels)\n",
    "\n",
    "        total_loss_recon += loss_recon.item()\n",
    "        total_loss_kl += loss_kl.item()\n",
    "        \n",
    "        # Loss backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    ## Evaluation\n",
    "    total_loss /= len(train_loader)\n",
    "    total_loss_recon /= len(train_loader)\n",
    "    total_loss_kl /= len(train_loader)\n",
    "    history[\"train\"][\"total_loss\"].append(total_loss)\n",
    "    history[\"train\"][\"recon_loss\"].append(total_loss_recon)\n",
    "    history[\"train\"][\"kl_loss\"].append(total_loss_kl)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        # TRAINING DATA\n",
    "        y_scores, y_true = torch.cat(all_preds), torch.cat(all_labels)\n",
    "        auc_score = compute_auc(y_scores, y_true)\n",
    "        avg_precision = compute_average_precision(y_scores, y_true)\n",
    "        history[\"train\"][\"auc\"].append(auc_score)\n",
    "        history[\"train\"][\"average_precision\"].append(avg_precision)\n",
    "\n",
    "        print(f\"TRAINING DATA\")\n",
    "        print(f\"Epoch {epoch}, Total Loss: {total_loss:.4f}, Rec. Loss: {total_loss_recon:.4f}, KL Loss: {total_loss_kl:.4f}\")\n",
    "        print(f\"AUC: {auc_score:.4f}, Average Precision: {avg_precision:.4f}\")\n",
    "\n",
    "        # VALIDATION DATA\n",
    "        val_metrics = evaluate(val_loader, model)\n",
    "        history[\"val\"][\"total_loss\"].append(val_metrics[\"total_loss\"])\n",
    "        history[\"val\"][\"recon_loss\"].append(val_metrics[\"total_loss_recon\"])\n",
    "        history[\"val\"][\"kl_loss\"].append(val_metrics[\"total_loss_kl\"])\n",
    "        history[\"val\"][\"auc\"].append(val_metrics[\"auc\"])\n",
    "        history[\"val\"][\"average_precision\"].append(val_metrics[\"average_precision\"])\n",
    "\n",
    "        print(f\"VALIDATION DATA\")\n",
    "        print(f\"Epoch {epoch}, Total Loss: {val_metrics['total_loss']:.4f}, Rec. Loss: {val_metrics['total_loss_recon']:.4f}, KL Loss: {val_metrics['total_loss_kl']:.4f}\")\n",
    "        print(f\"AUC: {val_metrics['auc']:.4f}, Average Precision: {val_metrics['average_precision']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77682c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NegativeSampling:\n",
    "#     def __init__(self, num_samples):\n",
    "#         self.num_samples = num_samples\n",
    "\n",
    "#     def sample(self, pos_edge_index, num_nodes):\n",
    "#         neg_src = torch.randint(0, num_nodes, (self.num_samples,))\n",
    "#         neg_dst = torch.randint(0, num_nodes, (self.num_samples,))\n",
    "#         neg_edge_index = torch.stack([neg_src, neg_dst], dim=0)\n",
    "#         return neg_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d1f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e56305",
   "metadata": {
    "id": "c6e56305"
   },
   "outputs": [],
   "source": [
    "class HybridBPRRatingAutoencoder(nn.Module):\n",
    "    def __init__(self, num_features_u, num_features_v, hidden_dim, latent_dim, rating_range=(1, 5)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rating_min, self.rating_max = rating_range\n",
    "\n",
    "        # Encoders (same as before)\n",
    "        self.encoder_u = nn.Sequential(\n",
    "            GCNConv(num_features_u, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            GCNConv(hidden_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "        self.encoder_v = nn.Sequential(\n",
    "            GCNConv(num_features_v, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            GCNConv(hidden_dim, latent_dim)\n",
    "        )\n",
    "\n",
    "        # Rating prediction head\n",
    "        self.rating_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x_u, x_v, edge_index):\n",
    "        z_u = self.encoder_u(x_u, edge_index)\n",
    "        z_v = self.encoder_v(x_v, edge_index)\n",
    "        return z_u, z_v\n",
    "\n",
    "    def predict_score(self, z_u, z_v, user_ids, item_ids):\n",
    "        \"\"\"For BPR ranking\"\"\"\n",
    "        user_emb = z_u[user_ids]\n",
    "        item_emb = z_v[item_ids]\n",
    "        return torch.sum(user_emb * item_emb, dim=1)\n",
    "\n",
    "    def predict_rating(self, z_u, z_v, user_ids, item_ids):\n",
    "        \"\"\"For explicit rating prediction\"\"\"\n",
    "        user_emb = z_u[user_ids]\n",
    "        item_emb = z_v[item_ids]\n",
    "        edge_embeddings = torch.cat([user_emb, item_emb], dim=1)\n",
    "\n",
    "        raw_ratings = self.rating_decoder(edge_embeddings)\n",
    "        ratings = raw_ratings * (self.rating_max - self.rating_min) + self.rating_min\n",
    "\n",
    "        return ratings.squeeze()\n",
    "\n",
    "    def forward(self, x_u, x_v, edge_index):\n",
    "        z_u, z_v = self.encode(x_u, x_v, edge_index)\n",
    "        return z_u, z_v\n",
    "\n",
    "def hybrid_loss(model, z_u, z_v,\n",
    "                # For explicit ratings\n",
    "                rating_user_ids, rating_item_ids, true_ratings, rating_mask,\n",
    "                # For BPR\n",
    "                bpr_user_ids, bpr_pos_items, bpr_neg_items,\n",
    "                rating_weight=1.0, bpr_weight=0.1):\n",
    "    \"\"\"\n",
    "    Combines rating prediction loss and BPR loss\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "\n",
    "    # Rating loss (only on observed ratings)\n",
    "    if rating_mask.sum() > 0:\n",
    "        observed_idx = rating_mask.bool()\n",
    "        pred_ratings = model.predict_rating(z_u, z_v,\n",
    "                                           rating_user_ids[observed_idx],\n",
    "                                           rating_item_ids[observed_idx])\n",
    "        rating_loss = F.mse_loss(pred_ratings, true_ratings[observed_idx])\n",
    "        total_loss += rating_weight * rating_loss\n",
    "\n",
    "    # BPR loss for ranking\n",
    "    if len(bpr_user_ids) > 0:\n",
    "        bpr_loss_val = bpr_loss(model, z_u, z_v, bpr_user_ids, bpr_pos_items, bpr_neg_items)\n",
    "        total_loss += bpr_weight * bpr_loss_val\n",
    "\n",
    "    return total_loss"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
